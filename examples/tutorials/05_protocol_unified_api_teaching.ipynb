{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dab7fda",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Create Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f640178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "from foodspec import FoodSpec\n",
    "\n",
    "print(\"Phase 1: Unified FoodSpec API - Complete Workflow Demo\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a588d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic Raman dataset\n",
    "print(\"\\n1. Creating synthetic spectroscopy data...\")\n",
    "np.random.seed(42)\n",
    "n_samples = 30\n",
    "n_wavenumbers = 200\n",
    "\n",
    "# Simulate Raman spectra (3 oil types with distinct signatures)\n",
    "x = np.random.randn(n_samples, n_wavenumbers) * 0.5 + np.linspace(0, 10, n_wavenumbers)\n",
    "wn = np.linspace(500, 2000, n_wavenumbers)\n",
    "\n",
    "oil_types = [\"olive\", \"sunflower\", \"canola\"] * 10\n",
    "metadata = pd.DataFrame({\n",
    "    \"sample_id\": [f\"oil_{i:03d}\" for i in range(n_samples)],\n",
    "    \"oil_type\": oil_types,\n",
    "    \"batch\": np.random.randint(1, 4, n_samples),\n",
    "})\n",
    "\n",
    "print(f\"   Created {n_samples} samples × {n_wavenumbers} wavenumbers\")\n",
    "print(f\"   Classes: {set(oil_types)}\")\n",
    "print(f\"   Wavenumber range: {wn[0]:.0f} - {wn[-1]:.0f} cm⁻¹\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2a42ea",
   "metadata": {},
   "source": [
    "## Step 2: Initialize FoodSpec and Execute Chainable Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bae129b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize FoodSpec\n",
    "print(\"\\n2. Initializing FoodSpec...\")\n",
    "fs = FoodSpec(\n",
    "    x,\n",
    "    wavenumbers=wn,\n",
    "    metadata=metadata,\n",
    "    modality=\"raman\",\n",
    "    kind=\"oils\",\n",
    ")\n",
    "print(f\"   ✓ Initialized: {len(fs.data)} samples, {fs.data.x.shape[1]} wavenumbers\")\n",
    "\n",
    "# Execute chainable workflow\n",
    "print(\"\\n3. Executing chainable workflow...\")\n",
    "print(\"   ├─ QC: outlier detection...\")\n",
    "fs.qc(method=\"isolation_forest\", threshold=0.1)\n",
    "\n",
    "print(\"   ├─ Preprocessing: baseline correction + smoothing...\")\n",
    "fs.preprocess(\n",
    "    baseline_correction=\"airpls\",\n",
    "    baseline_lambda=10000,\n",
    "    smoothing_method=\"savgol\",\n",
    "    smoothing_window=11,\n",
    ")\n",
    "\n",
    "print(\"   ├─ Training: random forest classifier...\")\n",
    "fs.train(\n",
    "    task=\"classification\",\n",
    "    target=\"oil_type\",\n",
    "    model_type=\"rf\",\n",
    "    cv_folds=3,\n",
    ")\n",
    "\n",
    "print(\"   └─ Workflow complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77fec22",
   "metadata": {},
   "source": [
    "## Step 3: Access Metrics and Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5787a81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n4. Workflow Summary:\")\n",
    "print(f\"   {fs.workflow_summary}\")\n",
    "\n",
    "print(\"\\n5. Metrics (Key Performance Indicators):\")\n",
    "if hasattr(fs, 'bundle') and hasattr(fs.bundle, 'metrics'):\n",
    "    for key, val in fs.bundle.metrics.items():\n",
    "        if isinstance(val, dict):\n",
    "            print(f\"   {key}:\")\n",
    "            for k, v in val.items():\n",
    "                if isinstance(v, float):\n",
    "                    print(f\"     - {k}: {v:.4f}\")\n",
    "        elif isinstance(val, float):\n",
    "            print(f\"   {key}: {val:.4f}\")\n",
    "        else:\n",
    "            print(f\"   {key}: {val}\")\n",
    "else:\n",
    "    print(\"   (Metrics available in fs.bundle.metrics after workflow)\")\n",
    "\n",
    "print(\"\\n6. Diagnostics Available:\")\n",
    "if hasattr(fs, 'bundle') and hasattr(fs.bundle, 'diagnostics'):\n",
    "    for key in fs.bundle.diagnostics.keys():\n",
    "        print(f\"   - {key}\")\n",
    "else:\n",
    "    print(\"   (Diagnostics available in fs.bundle.diagnostics)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f43582f",
   "metadata": {},
   "source": [
    "## Step 4: Export and Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b4f168",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n7. Exporting results...\")\n",
    "with TemporaryDirectory() as tmpdir:\n",
    "    out_path = Path(tmpdir)\n",
    "    fs.export(out_path)\n",
    "    \n",
    "    print(f\"   Exported to: {out_path}\")\n",
    "    print(f\"\\n   Output files:\")\n",
    "    for file in sorted(out_path.rglob(\"*\")):\n",
    "        if file.is_file():\n",
    "            size = file.stat().st_size\n",
    "            rel_path = file.relative_to(out_path)\n",
    "            print(f\"   ├─ {rel_path} ({size} bytes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126d0751",
   "metadata": {},
   "source": [
    "## Step 5: Key Takeaways\n",
    "\n",
    "### What We Learned:\n",
    "\n",
    "1. **Chainable API:** Methods return `self` for intuitive workflow composition\n",
    "2. **Built-in QC:** Automatic outlier detection protects downstream analyses\n",
    "3. **Standardized Preprocessing:** Proven baseline correction, smoothing, normalization\n",
    "4. **Reproducibility:** Full provenance tracking (metadata, parameters, versions)\n",
    "5. **Export Format:** Organized output with metrics, diagnostics, model artifacts\n",
    "\n",
    "### Workflow Advantages:\n",
    "\n",
    "- **Simplicity:** No manual intermediate file management\n",
    "- **Debugging:** Built-in diagnostics show what happened at each step\n",
    "- **Best Practices:** Defaults follow spectroscopy best practices\n",
    "- **Reproducibility:** Save/load workflow configuration as YAML/JSON\n",
    "- **Auditable:** Provenance file documents entire history\n",
    "\n",
    "### Customization:\n",
    "\n",
    "You can customize any step:\n",
    "```python\n",
    "fs.qc(method=\"mahalanobis\", threshold=2.0)  # Different outlier method\n",
    "fs.preprocess(baseline_correction=None)       # Skip baseline\n",
    "fs.train(model_type=\"svm\", kernel=\"rbf\")    # Different classifier\n",
    "```\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. Load your own data: `x, metadata = load_your_spectra()`\n",
    "2. Customize preprocessing parameters based on your instrument\n",
    "3. Explore different models (RF, SVM, Deep Learning)\n",
    "4. Compare cross-validation results\n",
    "5. Export and archive results with full provenance"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
